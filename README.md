Challenge Kaggle : "Natural Language Processing with Disaster Tweets"

Ce projet a √©t√© d√©velopp√© dans le cadre de la comp√©tition Kaggle "Getting Started". Il s'agit d'une introduction au traitement automatique du langage naturel (NLP).

üéØ Objectif du projet

L'objectif est de construire un mod√®le de classification binaire capable de distinguer les tweets qui mentionnent un d√©sastre r√©el de ceux qui ne le font pas, en utilisant un jeu de donn√©es d'environ 10 000 tweets annot√©s.

La performance du mod√®le est √©valu√©e √† l'aide du F1-score, une m√©trique qui √©quilibre la pr√©cision (precision) et le rappel (recall).

üíª Solution technique

La solution est impl√©ment√©e dans un notebook Jupyter (NLP_disaster_tweets.ipynb) et suit un pipeline de NLP standard :

    Exploration des donn√©es (EDA) : Analyse initiale du jeu de donn√©es pour comprendre la distribution des tweets, des mots-cl√©s et des localisations.

    Pr√©traitement du texte :

        Nettoyage des tweets (suppression des URL, des mentions @, de la ponctuation, etc.).

        Tokenisation et lemmatisation pour standardiser les mots.

        Gestion des stop words.

    Vectorisation des donn√©es : Transformation du texte en vecteurs num√©riques, en utilisant des techniques comme le TF-IDF (Term Frequency-Inverse Document Frequency) ou des embeddings de mots comme GloVe.

    Mod√©lisation : Entra√Ænement de plusieurs mod√®les de classification. Les mod√®les suivants ont √©t√© explor√©s :

        Classificateurs de base : Naive Bayes et Logistic Regression.

        Mod√®les de boosting : XGBoost.

        R√©seaux de neurones : Mod√®les de type RNN, LSTM ou Transformers (tels que BERT) pour capturer les s√©quences et le contexte.

    Optimisation et √©valuation : R√©glage des hyperparam√®tres et validation des performances √† l'aide du F1-score sur un jeu de donn√©es de validation.

üöÄ Guide d'utilisation

    Clone le d√©p√¥t.

    Installe les d√©pendances requises :
    Bash

    pip install pandas numpy scikit-learn nltk xgboost

    Si tu utilises des mod√®les de deep learning, il faudra aussi installer tensorflow ou pytorch.

    T√©l√©charge les jeux de donn√©es train.csv et test.csv depuis la page de la comp√©tition Kaggle et place-les dans le m√™me r√©pertoire que le notebook.

    Ex√©cute le notebook (NLP_disaster_tweets.ipynb) pas √† pas pour reproduire l'analyse et les pr√©dictions.

üìÅ Structure des fichiers

    NLP_disaster_tweets.ipynb : Le notebook Jupyter contenant le code de la solution.

    train.csv : Le jeu de donn√©es d'entra√Ænement.

    test.csv : Le jeu de donn√©es de test.

    sample_submission.csv : Un exemple de fichier de soumission.

    submission.csv : Le fichier de soumission g√©n√©r√© par le mod√®le.

    README.md : Ce fichier de documentation.
